# 粒子群优化 二

>在第一部分讲述了关于粒子群优化的原理，以及算法的整体流程结构，在这一部分，我们将会介绍在早期经典的PSO算法，并使用 MATLAB 以及 python 编写代码。相关代码请见 code 文件夹。

## 1 再论粒子群优化

粒子群优化中，越过最优的个体会被拉回去，所有粒子都保留了良好解决方案的知识。此外粒子群优化是有记忆的，在运行过程中会把历史最优粒子的位置进行记录，并且在后面的运行过程中不断对后面的粒子进行引导。
在《**A New Optimizer Using Particle Swarm Theory**》 一文中，作者 Russell Eberhart 和 James Kennedy 进一步论述了粒子群优化算法，在该文中描述了使用粒子群方法对非线性函数的优化。 讨论并比较了两种范式的实现，包括最近开发的面向本地的范式，描述了这两种范例的基准测试。在这其中提出的两种范式便是粒子群优化算法(Particle Swarm Optimization,PSO)的两种形式，但是一般我们更容易见到其中一种，也就是**GBEST** 模型，在第一次描述PSO算法中，就是以GBEST为例进行举例。除却 GBEST模型，在该文中还提出另外一种模型，那就是**LBEST** 模型。下面，我们将细致地介绍这两种模型。

## 2 GBEST模型

在之前已经介绍了粒子群优化算法的思想来源以及定义的对照表，所以想必大家对**gbest** 是有印象的。在第一篇文章中，我们将其称之为全局最优解。标准的“ GBEST”粒子群算法非常简单，它是开发的粒子群优化的原始形式。

### 2.1 算法执行流程

> - Step1：初始化种群，也即粒子数N，同时初始化每个粒子的速度和初始位置，维度为解的维度。
> - Step2：初始化pbest以及gbest，并给其赋初始值，可选择取值边界。定义最大迭代次数以及起始迭代值。这个设置就需要根据语言而定，比如MATLAB，其下标是从1开始，所以一般起始迭代我们设置为1.
> - Step3：对每一个粒子位置进行适应性评估，倘若当前位置优于历史最优位置，则更新该粒子的历史最优解。
> - Step4：从所有粒子的历史最优解获取适应性最优的那个位置，并与当前全局最优位置gbest适应性进行比较，如果适应性大于当前位置，则更新全局最优位置。
> - Step5：按照公式更新粒子速度，更新速度公式为：$v_i^d=v_i^d+c1\times rand_i^d\times (pBest_i^d-x_i^d)+c2\times rand_i^d\times (gBest^d-x_i^d)$
> - Step6：判断粒子速度是否超过取值范围，将超过取值范围的重新赋值（可以赋值为边界值，或者重新随机生成）。
> - Step7：按照公式更新粒子位置，更新粒子位置公式为：$x_i^d=x_i^d+v_i^d$
> - Step8：判断粒子位置是否超过取值范围，将超过取值范围的重新赋值（可以赋值为边界值，或者重新随机生成）。
> - Step9：判断迭代次数是否大于最大迭代次数，如不大于，则跳至Step3。否则输出最优解

## 3 LBEST 模型

除了GBEST模型之外，在这之后还提出了LBEST模型。在这种模型中，粒子仅具有自己的信息以及邻居的信息，而不是整个团队的全局最优信息。也就是说粒子没有了全局最优导向粒子，在这个过程中只会接收按照排序位置相邻的粒子的信息。粒子朝着由“pbest”和“ lbest”定义的点移动，而不是朝着“pbest”和“gbest”位置进行移动。这样的模型，粒子的多样性得到了很大程度上的维护，但是当粒子的相邻位置适应度较差时，粒子的适应值也会变差，同时，优于粒子的分布过于分散，导致粒子即使发现较好位置，也没有足够的粒子进行开发。可能会使其整体解的质量下降。
那么LBEST模型是如何进行更新的呢？在邻域= 2模型中，粒子（i）将其误差值与粒子（i-1）和粒子（i + 1）进行比较。
在这里，我们使用领域=2的模型进行描述。它的基本步骤和GBEST类似，只不过在更新的时候略有变化，同时也不再需要gbest变量来存储全局最优。

### 3.1 算法执行流程

> - Step1：初始化种群，也即粒子数N，同时初始化每个粒子的速度和初始位置，维度为解的维度。
> - Step2：初始化pbest，并给其赋初始值，可选择取值边界。定义最大迭代次数以及起始迭代值。这个设置就需要根据语言而定，比如MATLAB，其下标是从1开始，所以一般起始迭代我们设置为1.
> - Step3：对每一个粒子位置进行适应性评估，倘若当前位置优于历史最优位置，则更新该粒子的历史最优解。
> - Step4：按照公式更新粒子速度，更新速度公式为：$v_i^d=v_i^d+c1\times rand_i^d\times (pBest_i^d-x_i^d)+c2\times rand_{i-1}^d\times (x_{i-1}^d-x_i^d)+c3\times rand_{i+1}^d\times (x_{i+1}^d-x_i^d)$;在这里需要注意，我们采取首尾相连的措施，也就是第一个粒子的前一个粒子是最后一个粒子，同理，最后一个粒子的后一个粒子就是第一个粒子。
> - Step5：判断粒子速度是否超过取值范围，将超过取值范围的重新赋值（可以赋值为边界值，或者重新随机生成）。
> - Step6：按照公式更新粒子位置，更新粒子位置公式为：$x_i^d=x_i^d+v_i^d$
> - Step7：判断粒子位置是否超过取值范围，将超过取值范围的重新赋值（可以赋值为边界值，或者重新随机生成）。
> - Step8：判断迭代次数是否大于最大迭代次数，如不大于，则跳至Step3。否则输出最优解

### 3.2 非常重要

在邻域模型中，存在着很多邻域结构：例如二邻域、三邻域等多邻域结构，但是这些类似结构的编程方法都类似，无需多言。

但是在邻域模型中有一个非常重要的点，那就是对邻域的理解，或者说定义。一般说来可以分为两种：

- 第一种：逻辑上的邻域。在粒子群进行搜索的时候，每个粒子都会有一个位置下标，就如同我们给每个粒子进行编号一样，并且该编号不会随着后续程序的运行而发生改变。在该基础上实现多邻域粒子群优化代码会更加简单。但是会存在问题，那就是所谓的邻域粒子除了逻辑上相邻之外，在物理上并不相邻，因此在物理上或许并不能称为邻域。
- 第二种：物理上的邻域。从上面就可以很快明白，物理上的邻域就是在搜索过程中在粒子 $i$ 身边的粒子，因此在这种邻域结构中，就需要额外计算个粒子的相邻粒子，再根据计算的结果进行邻域更新。因此第二种邻域结构更符合正常的思维，但是要付出更大的空间以及时间。

## 4 $\omega$模型

Yuhui Shi 和 Russell Eberhart在1998年发表的一篇名叫《 **A Modified Particle Swarm Optimizer**》中对之前提出的GBEST模型进行进一步的分析，再该论文中，他们指出：该模型中的公式(1)是由三部分组成：第一部分是粒子的先前速度；第二和第三部分是有助于粒子速度变化的部分。通过公式(1)我们可以看到，如果没有$c1\times rand_i^d\times (pBest_i^d-x_i^d)$和$c2\times rand_i^d\times (gBest^d-x_i^d)$这两部分，那么粒子就会在速度所指向的方向直线来回运动，无法去探索更广泛的区域。除非解就在它们运行的直线上，还必须是在粒子所能到达的点的位置，否则无法寻找到最优解。

$$
v_i^d=v_i^d+c1\times rand_i^d\times (pBest_i^d-x_i^d)+c2\times rand_i^d\times (gBest^d-x_i^d) \tag{1}
$$

但是当没有第一部分时，粒子的飞行速度将只会受到局部最优位置以及全局最优位置的影响。当该是全局最优的时候，那么该粒子就会停在原地，直到其他粒子找到一个更优的解。

所以从上面的描述我们可以看出，**当粒子速度更新公式中缺少第一部分的时候，那么该粒子群展示的是局部搜索能力：“因为此时所有粒子都会围绕在全局最优处”。而当保留第一部分的时候，它其实是扩大了粒子群搜索空间，使得他们更有能力搜索到新的区域。**

**因此，通过添加第一部分，更有可能具有全局搜索能力。局部搜索和全局搜索都有助于解决某些类型的问题。 全局搜索和局部搜索之间存在权衡对于不同的问题，局部搜索能力和全局搜索能力之间应该有不同的平衡。** 考虑到这一点，将惯性权重w引入等式（1）中，如等式（2）所示。 这个 w 起到平衡全局搜索和局部搜索的作用，它可以是正常数，甚至是时间的正线性或非线性函数。

$$
v_i^d=\omega v_i^d+c1\times rand_i^d\times (pBest_i^d-x_i^d)+c2\times rand_i^d\times (gBest^d-x_i^d) \tag{2}
$$
同时，作者在论文也做了相关测试，从测试的数据可以发现：“范围[0.9,1.21] 是使用$\omega$得到效果最好的区域。 $\omega$ 在这个范围内的 PSO 将有更大的概率在合理的迭代次数找到全局最优值。 在该文的测试中，发现当 $\omega$=1.05时，PSO在迭代运行30次时都找到了全局最优值。 当 $\omega$ 在[0.9,1.2] 的范围内取值时，发现当$\omega$ = 0.9时，PSO 找到全局最优值的所需的平均迭代次数是最少的。”

>原文中也指出最优的方式 $\omega$ 一般是在[0.9,0.5]范围内线性递减

### 4.1 算法执行流程

该算法和 **GBSET** 模型的流程是一模一样的，唯一改变，就是速度更新公式由公式(1)改为公式(2).所以这里不再赘述该模型的算法流程。

## 源代码

> - **相应的代码在对应文件夹的code下，请需要者自行获取**

## 参考文献

[1]Eberhart, R. and J. Kennedy (1995). A new optimizer using particle swarm theory. Mhs95 Sixth International Symposium on Micro Machine & Human Science.
[2]Shi, Y. (1998). A Modified Particle Swarm Optimizer. Proc of IEEE Icec Conference.
